<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Preet Sojitra | MSCS Student</title>
    <link href="output.css" rel="stylesheet" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
      }
    </style>
  </head>
  <body class="bg-white text-gray-800 antialiased">
    <!-- Main Container -->
    <div class="container mx-auto max-w-3xl px-6 py-12">
      <!-- Header -->
      <header class="flex justify-between items-center mb-12">
        <h1 class="text-2xl font-bold text-gray-900">Preet Sojitra</h1>
        <!-- Navigation -->
        <nav class="space-x-6 text-base">
          <a href="#publications" class="text-gray-600 hover:text-red-600"
            >Publications</a
          >
          <a href="projects.html" class="text-gray-600 hover:text-red-600"
            >Projects</a
          >
          <a
            href="https://drive.google.com/file/d/1ukRQQrkv8llnHhzTtDpWGMEVDlPvptyk/view?usp=drive_link"
            target="_blank"
            class="text-gray-600 hover:text-red-600"
            >Resume</a
          >
        </nav>
      </header>

      <main>
        <!-- ====== About Me Section ====== -->
        <section id="about" class="mb-16">
          <div class="flex flex-col md:flex-row items-start gap-8">
            <!-- Text content on the left -->
            <div class="flex-grow md:basis-2/3">
              <h2 class="text-2xl font-bold mb-4">About Me</h2>
              <p class="mb-4 text-justify">
                Hello! I'm an incoming fall 2025 Master's student in Computer
                Science at UT Dallas. I'm one of those people who started out
                building websites and then fell down the rabbit hole of AI and
                Machine Learning. Now, instead of just making things look good,
                I'm trying to make them think, see, and chat.
              </p>
              <p class="mb-4 text-justify">
                My focus lies at the intersection of Computer Vision and Natural
                Language Processing. I love tackling projects that involve
                everything from fine-tuning large language models to developing
                systems that can interpret images and audio. I have a soft spot
                for elegant code and a strong belief that the best way to
                understand a concept is to build it from scratch.
              </p>

              <!-- "Contact Me" block -->
              <div class="mt-6">
                <strong class="font-bold">Contact Me:</strong>
                <div class="mt-2 text-gray-800">
                  <a
                    href="mailto:PreetMukeshkumar.Sojitra@UTDallas.edu"
                    class="text-red-600 hover:underline"
                    >Email</a
                  >
                  <span class="mx-2 text-gray-400">|</span>
                  <a
                    href="https://github.com/Preet-Sojitra"
                    target="_blank"
                    class="text-red-600 hover:underline"
                    >GitHub</a
                  >
                  <span class="mx-2 text-gray-400">|</span>
                  <a
                    href="https://github.com/Preet-Sojitra"
                    target="_blank"
                    class="text-red-600 hover:underline"
                    >LinkedIn</a
                  >
                  <span class="mx-2 text-gray-400">|</span>
                  <a
                    href="https://x.com/Preet_Sojitra03"
                    target="_blank"
                    class="text-red-600 hover:underline"
                    >Twitter</a
                  >
                </div>
              </div>
            </div>
            <!-- Profile Picture -->
            <div
              class="md:basis-1/3 flex justify-center md:justify-end md:self-center md:mt-[-4rem]"
            >
              <img
                src="photo.jpeg"
                alt="A photo of Preet Sojitra"
                class="w-32 h-32 md:w-48 md:h-48 rounded-full object-cover shadow-lg"
              />
            </div>
          </div>
        </section>

        <!-- ====== Research Interests Section ====== -->
        <section id="research" class="mb-16">
          <h2 class="text-2xl font-bold mb-4">Research Interests</h2>
          <p class="mb-4">
            I am fascinated by the challenge of creating machines that can
            perceive and reason about the world in a holistic way, much like
            humans do. My primary research interest, therefore, lies in
            Multimodal Machine Learning, which integrates different data types
            like vision, language, and audio.
          </p>
          <p class="mb-4">
            My previous work with audio data, such as in "Depression Detection
            through Speech Analysis" and time-series classification, has given
            me a solid foundation. I am now eager to expand upon this by
            exploring how visual and linguistic information can be combined to
            create more robust and context-aware AI systems
          </p>
          <p>
            As a thesis-track Master's student, I am actively seeking
            opportunities to contribute to ongoing lab projects in these areas.
            I am a dedicated and fast learner, eager to engage with challenging
            research questions and support the lab's goals through meaningful
            and consistent work.
          </p>
        </section>

        <!-- ====== Publications Section ====== -->
        <section id="publications" class="mb-16">
          <h2 class="text-2xl font-bold mb-4">Publications</h2>
          <div class="space-y-4">
            <div>
              <p class="font-bold">
                AI-Driven Gait Classification Using Portable Wearable Sensors:
                Advances and Case Study
              </p>
              <p class="text-sm text-gray-600">
                Sonam Nahar, Preet Sojitra, and Vineet Vashista
              </p>
              <p class="text-sm text-gray-600 italic">
                Chapter in "Design and Control of Rehabilitation Robots",
                Springer, July 2025.
              </p>
              <div class="mt-1 space-x-4">
                <a
                  href="https://drive.google.com/file/d/1dMLkPAirWq7VOcFQsJevYonJvPax4_50/view?usp=sharing"
                  target="_blank"
                  class="text-red-600 hover:underline"
                  >[PDF]</a
                >
                <!-- Link to the official Springer page (even if paywalled) -->
                <a
                  href="https://doi.org/10.1007/978-3-031-86977-8_9"
                  target="_blank"
                  class="text-red-600 hover:underline"
                  >[Official Version]</a
                >
                <!-- You can add a BibTeX link later if you want -->
                <!-- <a href="#" class="text-red-600 hover:underline">[BibTeX]</a> -->
              </div>
            </div>
            <!-- Add more publications here -->
          </div>
        </section>

        <!-- ====== Experience Section ====== -->
        <section id="experience" class="mb-16">
          <h2 class="text-2xl font-bold mb-4">Experience</h2>

          <div class="space-y-12">
            <!-- Experience 1: 9series -->
            <div class="border-l-4 border-gray-500 pl-4 py-2">
              <h3 class="text-lg font-bold">
                AI & NLP Research Intern @ 9series Pvt Ltd
              </h3>
              <p class="text-sm text-gray-600">Feb 2025 - Jun 2025</p>

              <div class="mt-4">
                <strong class="text-md">
                  Project: Production-Scale Counterfeit Product
                  Detection</strong
                >
                <ul class="list-disc list-inside mt-2 text-gray-700 space-y-1">
                  <li>
                    Engineered an end-to-end computer vision system using YOLOv8
                    to detect and classify counterfeit luxury goods, achieving
                    over 95% classification accuracy on real-world data.
                  </li>
                  <li>
                    Developed and deployed the system's backend with FastAPI on
                    AWS, integrating it directly into the client's Shopify store
                    and e-commerce platform.
                  </li>
                  <li>
                    Architected and implemented a scalable inference pipeline
                    using Celery and Redis to manage high-volume asynchronous
                    requests, significantly reducing API response latency.
                  </li>
                  <li>
                    Utilized explainable AI techniques like Grad-CAM to validate
                    model behavior and ensure decision transparency.
                  </li>
                </ul>
              </div>

              <div class="mt-6">
                <strong class="text-md">
                  Project: R&D in Conversational AI for Dispute
                  Resolution</strong
                >
                <ul class="list-disc list-inside mt-2 text-gray-700 space-y-1">
                  <li>
                    Led the fine-tuning of Large Language Models (Llama 3,
                    Gemma) to automate the classification of customer chargeback
                    disputes.
                  </li>
                  <li>
                    Generated a synthetic, multi-turn conversational dataset to
                    train the models to identify valid disputes by interacting
                    with customers.
                  </li>
                  <li>
                    Implemented LoRA-based fine-tuning using Unsloth and Hugging
                    Face, successfully teaching the model to recognize dispute
                    categories and adopt a specific conversational tone.
                  </li>
                </ul>
              </div>
            </div>

            <!-- Experience 2: Research Internship -->
            <div class="border-l-4 border-gray-500 pl-4 py-2">
              <h3 class="text-lg font-bold">
                Research Intern @ HCR Lab, IIT Gandhinagar
              </h3>
              <p class="text-sm text-gray-600">May 2024 - Oct 2024</p>
              <ul class="list-disc list-inside mt-2 text-gray-700">
                <li>
                  Conducted a 5-month research project on AI-driven gait
                  analysis using wearable sensor data, managing the full project
                  lifecycle from participant data collection to final analysis.
                </li>
                <li>
                  Developed and benchmarked deep learning models (GRUs and
                  1D-CNNs) for time-series classification of IMU sensor data to
                  identify gait patterns.
                </li>
                <li>
                  This work culminated in a book chapter published by Springer
                  (see Publications section).
                </li>
              </ul>
            </div>
            <!-- More experience here -->
          </div>
        </section>

        <!-- ====== Projects Section ====== -->
        <section id="projects" class="mb-16">
          <h2 class="text-2xl font-bold mb-4">Featured Projects</h2>
          <div class="space-y-8">
            <!-- Project 1: Depression Detection -->
            <div class="border-l-4 border-red-500 pl-4 py-2">
              <h3 class="text-lg font-bold">
                Depression Detection through Speech Analysis
              </h3>
              <p class="mt-1">
                An end-to-end research project to detect depression from speech
                recordings using the DAIC-WOZ dataset. Systematically evaluated
                a range of models, from classic CNNs (VGGNet, ResNet) to Vision
                Transformers (ViT), on spectrograms and raw audio data.
              </p>
              <p class="mt-2 text-sm text-gray-600">
                <strong>Accomplishment:</strong> Gained experience in the full
                research pipeline, including feature engineering for audio,
                comparative model benchmarking, and handling class imbalance.
              </p>
              <div class="mt-2 space-x-4">
                <a
                  href="https://github.com/Preet-Sojitra/depression_detection"
                  target="_blank"
                  class="text-red-600 hover:underline"
                  >[GitHub]</a
                >
              </div>
            </div>

            <!-- Project 2: imgcv -->
            <div class="border-l-4 border-red-500 pl-4 py-2">
              <h3 class="text-lg font-bold">
                imgcv: A Image Processing Library from Scratch
              </h3>
              <p class="mt-1">
                Developed and published a Python package on PyPI that
                re-implements core image processing OpenCV functions from the
                ground up using only NumPy. The goal was to build a deep,
                fundamental understanding of how computer vision and image
                processing algorithms work under the hood.
              </p>
              <p class="mt-2 text-sm text-gray-600">
                <strong>Accomplishment:</strong> Solidified my understanding of
                algorithms for filtering, color space manipulation,
                morphological operations, and edge detection.
              </p>
              <div class="mt-2 space-x-4">
                <a
                  href="https://github.com/Preet-Sojitra/imgcv"
                  target="_blank"
                  class="text-red-600 hover:underline"
                  >[GitHub]</a
                >
                <a
                  href="https://pypi.org/project/imgcv/"
                  target="_blank"
                  class="text-red-600 hover:underline"
                  >[PyPI Package]</a
                >
              </div>
            </div>

            <!-- Project 3: nanoGPT -->
            <div class="border-l-4 border-red-500 pl-4 py-2">
              <h3 class="text-lg font-bold">
                nanoGPT: Building a Transformer from Scratch
              </h3>
              <p class="mt-1">
                Implemented a decoder-only GPT-style language model from scratch
                in PyTorch, training it to generate text in the style of
                Shakespeare. This project was a deep dive into the fundamental
                mechanics of the Transformer architecture.
              </p>
              <p class="mt-2 text-sm text-gray-600">
                <strong>Accomplishment:</strong> Gained a code-level
                understanding of self-attention, which I am now extending to
                train a similar model on the more complex Sanskrit language.
              </p>
              <div class="mt-2 space-x-4">
                <a
                  href="https://www.kaggle.com/code/preetsojitra/nanogpt-decoder-only-transformer"
                  target="_blank"
                  class="text-red-600 hover:underline"
                  >[Kaggle]</a
                >
              </div>
            </div>
          </div>
          <div class="text-center mt-8">
            <a
              href="projects.html"
              class="text-red-600 hover:underline font-semibold"
              >View All Projects →</a
            >
          </div>
        </section>
      </main>

      <!-- Footer / Contact Section -->
      <footer class="text-center pt-8 border-t border-gray-200">
        <p class="text-sm text-gray-400 mt-8">
          © 2025 Preet Sojitra. Built with HTML & Tailwind CSS.
        </p>
      </footer>
    </div>
  </body>
</html>
